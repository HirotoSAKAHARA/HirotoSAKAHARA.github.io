<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai - reccurent neural network - base </title>
<base href="../../" />


<link rel="stylesheet" href="style.css">
<!-- 数式を使う宣言-->
<script>
  window.MathJax = {
    tex: {
macros: {
x: "{\\times}",
bm: ["{\\boldsymbol{#1}}",1],
dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
},
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true,
tags: "ams",
autoload: {
color: [],
colorV2: ['color']
},
packages: {'[+]': ['noerrors']}
    },
    chtml: {
matchFontHeight: false,
displayAlign: "left",
displayIndent: "2em"
    },
    options: {
renderActions: {
/* add a new named action to render <script type="math/tex"> */
find_script_mathtex: [10, function (doc) {
for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
const display = !!node.type.match(/; *mode=display/);
const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
const text = document.createTextNode('');
node.parentNode.replaceChild(text, node);
math.start = {node: text, delim: '', n: 0};
math.end = {node: text, delim: '', n: 0};
doc.math.push(math);
}
}, '']
}
    },
    loader: {
load: ['[tex]/noerrors']
    }
  };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>

</head>

<body>
<main>

<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle"> : 人工知能 - 再帰型ニューラルネットワーク</span>
  </div>

</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日:' + document.lastModified);
</script>
：
</div>
</div>

<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h1>基礎</h1>
    <h2>特徴</h2>
        <div><div class="hidden_show">
    
  フィードバック結合をもつ。漸化式のような構造を持つ。
    最も簡単な構造のRNNの式は以下の式で表され、
    構造は、入力層\(x_i\)、1層以上の中間層(隠れ層)\(h_i\)、出力層\(y_i\)からなる下図で示され、
    １時刻前の中間層の出力を次の中間層に利用することで、それまでの状態変化を全て反映する。
    $$
h_t = f(Ux_t + Wh_{t-1} + b_h)
    $$
    $$
y_t = g(Vh_t + b_y)
    $$

    <img src="out\ai\RNN_base.png" alt="RNN"/>
        </div></div>
    <h2>応用分野</h2>
        <div><div class="hidden_show">
    
  手書き文字認識、音声認識、手書き文字生成、系列学習、機械翻訳、画像脚注付け、構文解析、プログラムコード生成
        </div></div>
    <h2>RNNの種類と応用例</h2>
        <div><div class="hidden_show">
    
  入出力の数により幾つかの種類に分けることができる。
    <dl>
<dt>one-to-one</dt>
<dd>画像分類</dd>
<dt>one-to-many</dt>
<dd>中間層が時間発展で変わっていく : 画像脚注付き</dd>
<dt>many-to-one<dt>
<dd>入力が沢山で出力が１つ：感性分析(レビュー文を見せて星の数を予想する)</dd>
<dt>many-to-many<dt>
<dd>入力と出力がたくさん（通常のrnn)：機械翻訳</dd>
<dt>many-to-many(逐次)</dt>
<dd>ビデオ分類</dd>
    </dl>

    <h3>Elman Net<span class="small">エルマンネット</span></h3>
(入力層+context)＋中間層＋出力層となっており、contextは1時刻前の中間層（内部状態）をコピーする。

    <h3>Jordan Net<span class="small"> : ジョーダンネット</span></h3>
(入力層＋context)＋中間層＋出力層となっており、contextは1時刻前の出力層をコピーする。

        </div></div>
    <h2>課題</h2>
        <div><div class="hidden_show">
    
  <h3>long term dependency(長距離依存)</h3>
いくつか前の情報に依存する時の対策は難しく、
再帰結合係数行列の時間発展に関して指数的に作用（勾配爆発）

    <h3> the gradient exploring problem(勾配爆発問題)</h3>
RNNの逆伝播において、重み行列を掛けていくことにより、
勾配が指数関数的に大きくなってしまうこと。

    </div></div>
<div class="end_of_page_margin"></div>
<div class="end_of_page">
<a class="prev" href="03_ai/06_convolution_neural_network/04_implementation.html">実装</a>
<a class="upper" href="index.html">上：ホーム</a>
<a class="next" href="03_ai/07_reccurent_neural_network/02_LSTM.html">LSTM</a>
</div>
</main>
</body>
</html>
