<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai - learning methods - support vector machine one </title>
<base href="../../" />

<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
tex: {
macros: {
x: "{\\times}",
bm: ["{\\boldsymbol{#1}}",1],
dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
},
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true,
tags: "ams",
autoload: {
color: [],
colorV2: ['color']
},
packages: {'[+]': ['noerrors']}
},
chtml: {
matchFontHeight: false,
displayAlign: "left",
displayIndent: "2em"
},
options: {
renderActions: {
/* add a new named action to render <script type="math/tex"> */
find_script_mathtex: [10, function (doc) {
for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
const display = !!node.type.match(/; *mode=display/);
const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
const text = document.createTextNode('');
node.parentNode.replaceChild(text, node);
math.start = {node: text, delim: '', n: 0};
math.end = {node: text, delim: '', n: 0};
doc.math.push(math);
}
}, '']
}
},
loader: {
load: ['[tex]/noerrors']
}
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle"> : 人工知能 - 非深層学習系の学習手法</span>
  </div>

</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日 : ' + document.lastModified);
</script>
<!--...........................更新内容............................-->
：双対問題、カーネル関数について記述
</div>
</div>

<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h1>サポートベクトルマシン(教師なし学習、1クラス分類)</h1>
  <h2>概要</h2>
    <div><div class="hidden_show">
    ある分類に当てはまるベクトル\(\bm{x}\)が\(f(\bm{x}) \ge 0\)、そうでないものは\(f(\bm{x}) \le 0\)となるような\(f(\bm{x})\)を見つけることを目的とする。
    ２つのベクトルの類似度が高ければ高いほど大きな値をとるカーネル関数\( K(\bm{x}, \bm{x}') = \phi(\bm{x}_i)^\top\phi(\bm{x}_j) \)を考えると、
    １クラスsvmの分類問題は、決定関数 \(f(\bm{x}) = \bm{w}^\top\phi(\bm{x}) - \rho\)で分類する問題となる。
    ここで、\(\rho\)はバイアス\(b\)の符号を逆にしたものであり、境界\(f(\bm{x})\)と原点の距離は\( \frac{\rho}{\|w\|} \)と表される。
    この時１クラスSVMは以下のように書ける。
    $$
      \min_{\bm{w}, \rho \in \mathbb{R}} \frac{1}{2} \|w\|^2 - \rho + \frac{1}{n\nu} \sum_{i \in [n]} max{\{0, -(\bm{w}^\top \phi(\bm{x}_i) - \rho)\}}
    $$
    ここで、\( \nu \)は学習後の関数\(f(x)\)の偽陽性率の割合である。
    さらに、スラック変数\(\{\xi_i\}_{i \in [n]}\)を使うと、以下の式と制約に書き直せる。
    $$
      \min_{\bm{w} \in \chi, \rho \in \mathbb{R}, \xi \in \mathbb{R}^n } \frac{1}{2} \|w\|^2 - \rho + \frac{1}{n\nu} \sum_{i \in [n]} \xi_i
    $$
    $$
      \text{        s.t. } \xi_i \gt - (\bm{w}^\top \phi(\bm{x}_i) - \rho), \xi_i \gt 0, \forall_i \in [n]
    $$

    この主問題の双対問題は以下のように書ける。
    $$
      \min_{\bm{\alpha} \in \mathbb{R}^n} \frac{1}{2} \sum_{i \in [n]} \sum_{j \in [n]} \alpha_i \alpha_j K(\bm{x}_i, \bm{x}_j)
    $$
    $$
      \text{        s.t. } \begin{eqnarray*} 
        0 \le \alpha_i \le \frac{1}{n\nu}, \forall_i \in [n] \\
          \sum_{i \in [n]} \alpha_i = 1

      \end{eqnarray*}
    $$

    </div></div>
  <h2>参考文献、サイト</h2>
    <div><div class="hidden_show">
    <ol>
      <li><cite><a href="https://www.kspub.co.jp/book/detail/1529069.html">竹内一郎, 烏山昌幸, "サポートベクトルマシン",2015,講談社サイエンティフィク</li>
    </ol>

    </div></div>
<div class="end_of_page_margin"></div>
<div class="end_of_page">
<a class="prev" href="3_ai/4_learning_methods/4_support_vector_machine_regression.html">サポートベクトルマシン(回帰)</a>
<a class="upper" href="index.html">上：ホーム</a>
<a class="next" href="3_ai/4_learning_methods/6_k_nearest_neighbor.html">k近傍法</a>
</div>
</main>
</body>
</html>

