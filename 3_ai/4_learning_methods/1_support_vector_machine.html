<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai - learning methods - support vector machine </title>
<base href="../../" />

<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
tex: {
macros: {
x: "{\\times}",
bm: ["{\\boldsymbol{#1}}",1],
dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
},
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true,
tags: "ams",
autoload: {
color: [],
colorV2: ['color']
},
packages: {'[+]': ['noerrors']}
},
chtml: {
matchFontHeight: false,
displayAlign: "left",
displayIndent: "2em"
},
options: {
renderActions: {
/* add a new named action to render <script type="math/tex"> */
find_script_mathtex: [10, function (doc) {
for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
const display = !!node.type.match(/; *mode=display/);
const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
const text = document.createTextNode('');
node.parentNode.replaceChild(text, node);
math.start = {node: text, delim: '', n: 0};
math.end = {node: text, delim: '', n: 0};
doc.math.push(math);
}
}, '']
}
},
loader: {
load: ['[tex]/noerrors']
}
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle"> : 人工知能 - 非深層学習系の学習手法</span>
  </div>

</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日 : ' + document.lastModified);
</script>
<!--...........................更新内容............................-->
：
</div>
</div>

<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h1>サポートベクトルマシン</h1>
  <h2>英語名、略称など</h2>
    <div><div class="hidden_show">
    
  SVN、Support Vector Machine。分類に使われる場合はSupport Vector Classification(SVC)とも。

    </div></div>
  <h2>ターゲットタスク</h2>
    <div><div class="hidden_show">
    分類、回帰、クラスタリングなど、ほぼあらゆる機械学習に使われる。

    </div></div>
  <h2>2クラス分類</h2>
    <div><div class="hidden_show">
    <h3>ハードマージン</h3>
      訓練集合内のデータを正しく分類できる直線\(f(\bm{x}) = \bm{w}^\mathrm{T}\bm{x}+b\)が求められる場合、訓練集合は\(f(\bm{x})\)によって分離可能(separable)であると表現される。この時、\(f(\bm{x})\)は無数に存在するが、SVNでは\(f(\bm{x})\)と両方のクラスの最近隣接点の距離の和を最大にする、つまりマージン最大化(margin maximization)するパラメータを選択する。この場合、SVMは以下の最適化問題によって定式化できる。
      $$
        \max_{\bm{w},b,M}\frac{M}{||\bm{w}||}
      $$
      $$
        \text{        s.t. } y_i(\bm{w}^\mathrm{T}\bm{x}_i+b) \ge M, i \in [n]
      $$
      この式を更に\(\tilde{\bm{w}} = \bm{w}/M\), \(\tilde{b} = b/M\)で置き換え、変形した以下の式が、一般的なハードマージンの定式化となる。
      $$
        \min_{\bm{\tilde{w}},b}||\bm{\tilde{w}}||
      $$
      $$
        \text{        s.t. } y_i(\bm{\tilde{w}}^\mathrm{T}\bm{x}_i+\tilde{b}) \ge 1, i \in [n]
      $$
    <h3>ソフトマージン</h3>
      
    </div></div>
  <h2>多クラス分類</h2>
    <div><div class="hidden_show">
    
    </div></div>
  <h2>回帰</h2>
    <div><div class="hidden_show">

    </div></div>
  <h2>１クラスSVM</h2>
    <div><div class="hidden_show">
    <h3>概要</h3>
      教師なし学習のためのSVM
      
    </div></div>
  <h2>カーネル関数</h2>
    <div><div class="hidden_show">
    

    </div></div>
<div class="end_of_page_margin"></div>
<div class="end_of_page">
<a class="prev" href="3_ai/3_evaluation/6_standard_problem.html">標準問題</a>
<a class="upper" href="index.html">上：ホーム</a>
<a class="next" href="3_ai/4_learning_methods/2_k_nearest_neighbor.html">k近傍法</a>
</div>
</main>
</body>
</html>

