<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai</title>
<base href="../" />


<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
      tex: {
        macros: {
        x: "{\\times}",
        bm: ["{\\boldsymbol{#1}}",1],
        dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
        },
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true,
        tags: "ams",
        autoload: {
          color: [],
          colorV2: ['color']
        },
        packages: {'[+]': ['noerrors']}
      },
      chtml: {
        matchFontHeight: false,
        displayAlign: "left",
        displayIndent: "2em"
      },
      options: {
        renderActions: {
          /* add a new named action to render <script type="math/tex"> */
          find_script_mathtex: [10, function (doc) {
            for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            }
          }, '']
        }
      },
      loader: {
        load: ['[tex]/noerrors']
      }
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle">
      - AI
    </span>
  </div>
</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日:' + document.lastModified);
</script>
<!--...........................更新内容............................-->
： 最小二乗法の詳細やNNの指標の内容などについて追記
</div>

 <div class="navigation">
<ul>
  <li><a href="index.html">home</a></li>
  <li><a href="mobile_robot/index.html">移動ロボット</a></li>
  <li><a href="ai/index.html">AI</a></li>
  <li><a href="math/index.html">数学</a></li>
  <li><a href="other/index.html">その他</a></li>
</ul>
</div>

<!--*********************************本文*********************************-->
<h1>AI</h1>

<h2>教師あり学習</h2>
  <h3>概要</h3>
    <div class="hidden_box">
    <label for="label1-1">[+]</label>
    <input type="checkbox" id="label1-1"/>
    <div class="hidden_show">
      事前に与えられたデータをいわば例題とみなして、それをガイドに学習を行う    
    </div></div>
 <h3>分類手法</h3>
    <div class="hidden_box">
    <label for="label1-2">[+]</label>
    <input type="checkbox" id="label1-2"/>
    <div class="hidden_show">

    <h4>最近傍法,k近傍法</h4>
        空間上の点を抽出したとき、隣接の学習済みの点のラベル情報から抽出点のラベル情報を決定する
        関数が想定されていないノンパラメトリックで
        教師データをそのまま丸暗記する怠惰学習(lazy learner)である。
        kの選択や特徴尺度の選択などのパラメータ選択が必要である。
        また、最近傍探索アルゴリズムが計算速度において重要となる

    <h4>ナイーブベイズ</h4>
        
    <h4>boosting, ブースティング</h4>
   　　機械学習のメタアルゴリズムで、ほかの学習アルゴリズムと組み合わせて利用する。adaBoostが有名
       前の分類器の間違いに応じてデータの重みを調整する。
   　　真の分類と若干の相関がある弱い分類器を組み合わせることにより、強い学習機を生成できるかを示す。

    <h4><a href="ai/neural_network.html">Neural Network(NN, ニューラルネットワーク)</a></h4>

    </div> </div>

  <h3>回帰手法</h3>
    <div class="hidden_box">
    <label for="label1-3">[+]</label>
    <input type="checkbox" id="label1-3"/>
    <div class="hidden_show">

    <h4>解析的解法と探索的解法</h4>

    <h4>線形回帰</h4>
      解析的手法の代表的なもので、
      \(z = w_0 + w_1u_1 + \cdots + w_uu_n + e\) となる関係を示したもの。以下に分類される。
    <dl>
      <dt>単回帰</dt>
      <dd>変数が１つの１次式(\( z = wu + w_0 \) )の回帰。導出される1次式を回帰直線と呼ぶ。</dd>
      <dt>多項回帰</dt>
      <dd>変数が１つのn次式(\( y = w_1u + w_2u^2 + \cdot + w_nu^n + w_0 \))の回帰</dd>
      <dt>重回帰</dt>
      <dd>変数が複数ある式(\( y = w_1u_1 + w_2u_2 + \cdot + w_nu_n + w_0 \))の回帰</dd>
    </dl>

    <h5>最小二乗法</h5>
      <div>線形回帰を求める手法。</div>
      <div>入力の組\(\bm{U}\)、出力の組\(\bm{z}\)が与えられた時、
      \(\bm{z} \simeq \bm{Uw}\)となる係数の組\(\bm{w}\)を、
      残差平方和 \( \|\bm{Uw} - \bm{z}\| \) を最小にするという条件で求める。</div>
      <div>正規方程式 \( \bm{U^{\mathrm{T}}Uw} = \bm{U^\mathrm{T}z} \)により、
      より直接的には以下の式により$\bm{w}$を算出する。</div>
      $$
        \bm{w} = (\bm{U}^{\mathrm{T}}\bm{U})^{-1}\bm{U}^{\mathrm{T}} \bm{z}
      $$
  
    <h4>ロジスティック回帰</h4>
    確率やダミー変数について分析、予測するのに使われる。

    <h4>サポートベクターマシン SVC, SVM</h4>

    <h4><a href="ai/neural_network.html">Neural Network(NN, ニューラルネットワーク)</a></h4>

    </div> </div>
 
<h2>教師なし学習</h2>
  <h3>概要</h3>
    <div class="hidden_box">
    <label for="label2-1">[+]</label>
    <input type="checkbox" id="label2-1"/>
    <div class="hidden_show">
    学習データを教えることによって、それぞれの点の特徴の分類を行う。
    </div></div>
  <h3>分類手法(クラスタリング)</h3>
    <div class="hidden_box">
    <label for="label2-2">[+]</label>
    <input type="checkbox" id="label2-2"/>
    <div class="hidden_show">

    <h4>Self Organizing Map (SOM, 自己組織化)</h4>
      <dl>
      <dt>マルスバーグの自己組織化</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>コホネンの自己組織化</dt>
      <dd>
        ランダムなベクトルからなる行列を用意する。入力ノード群を用意し、
        そのノードに一番近い点とそのノードの隣接点に暴露することを繰り返すことで分類ができる。
        (結果的に入力ノードが消える場合もある）
      </dd>
      <dt>リンスカーの受容野形成の自己組織化</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>オジャのSOMの自己組織化</dt>
      <dd>
        Todo:内容
      </dd>
      </dl>
    <h4>k means クラスタリング</h4>

    <h4><a href="ai/neural_network.html">Neural Network(NN, ニューラルネットワーク)</a></h4>
 
    </div></div>

  <h3>次元圧縮手法</h3>
    <div class="hidden_box">
    <label for="label2-3">[+]</label>
    <input type="checkbox" id="label2-3"/>
    <div class="hidden_show">

    <h4>PCA 主成分分析</h4>
    <h4>Independent component analysis (ICA 独立成分分析)</h4>
      <h5>内容</h5>
      ブラインドソース分離(多変量の信号を複数の加法的な成分に分離する)
      ための計算手法。PCAでは合わさったデータの主成分が出力され、分離できない
      ネゲントロピー(負のエントロピー)を考える
      <h5>応用例</h5>
      MEG、画像の雑音除去、保険データ
    <h4>非負行列因子化(NMF)</h4>
      行列Xを行列Wと行列Hで近似する方法。値は正の値だけ取る。
      画像のパーツパーツを抽出できる。
    <h4>Natrix Factorization(行列因子化)</h4>
      協調フィルタリングとして働き、Netflix映画のおすすめができるようになった。
      目標関数はRSMEで、正則化により過学習を抑制。NMFとあまり変わらない。
      
    <h4>VQ(Vector Quantaization、ベクトル量子化)</h4>
      典型的な画像を組み合わせた画像を作ることができる。

    <h4>t-Stocastic Neighbor Embedding(t-SNE)</h4>
      t分布を用いた確率的な視覚化手法で、多様体(manifold)の次元圧縮。
      多様体とは、近傍ではユークリッド距離系となっているが、
      全体としてはユークリッド距離系となっていない。
      抽象的に言えば、スイスロール上のデータを広げて２次元にして表示できる。


    </div></div>

<h2>強化学習</h2>

  <h3>基本</h3>
    <div class="hidden_box">
    <label for="label-RL_base">[+]</label>
    <input type="checkbox" id="label-RL_base"/>
    <div class="hidden_show">
      <h4>概要</h4>
        動的で複雑な環境に対応する学習。環境や外部刺激がある中で、正しく意思決定する方法。
        エージェントが行動し、行動によって応対が変化し、環境から報酬を与えられ、累積報酬の最大化を目指す。
        外部状況の表現をNNで行うことで高精度化

      <h4>用語</h4>
        <dl>
          <dt>報酬</dt>
          <dd>
          その行動が良かったか悪かったかを示す。スカラ値。行動への具体的なヒントにならない、すぐに与えられない場合もある。
          </dd>
          <dt>収益</dt>
          <dd>即時報酬＋Σ(割引率*未来の報酬)</dd>
          <dt>価値</dt>
          <dd>
          その行動が良かったか悪かったかを示す。行動への具体的なヒントにならない、すぐに与えられない場合もある。
          </dd>
          <dt>行為</dt>
          <dd></dd>
          <dt>状態</dt> 
          <dd></dd>
          <dt>TD学習</dt> 
          <dd></dd>
          <dt>ポリシー</dt>
          <dd> 最適なポリシーを確率的に定義する。</dd>
          <dt>価値観数</dt>
          <dd> あるポリシーを行ったときの、報酬の期待値。 行動価値観数vと行動価値観数qがある。
          状態価値関数vはある状態の価値を再帰的に書いたもの。行動価値関数qは"ある行動を取ったとき"の価値を示す。
          </dd>
          <dt>最適価値観数</dt>
          <dd> 価値関数の中で最大値となるもの。一般にはベルマン方程式となり、計算するのは非常に難しい</dd>

          <dt>探索と利用のジレンマ</dt>
          <dd>ある行動が最適かどうかは別の行動をしないとわからないが、最良の行動と決定している別の行動ばかりしていると良い行動を選べない</dd>
        </dl>

        <h4>モデル</h4>
          <dl>
            <dt>価値ベース</dt> 
            <dd>
            方策なし、価値観数あり
            </dd>
            <dt>方策ベース</dt>
            <dd>
            方策あり、価値観数あり
            </dd>
            <dt>アクタークリティック</dt>
            <dd>
            方策を取った行動で批判しながら行動する。
            </dd>
          </dl>
          </div></div>

  <h3>マルコフ決定過程</h3>
    <div class="hidden_box">
    <label for="label-marcov">[+]</label>
    <input type="checkbox" id="label-marcov"/>
    <div class="hidden_show">

    <h4>マルコフ性、マルコフ性</h4>
      一つ前の状態の条件付き確率（一つ前の状態の条件付き確率）。それまでの状態は考慮されない。
    <h4>POMDP</h4>
      部分観測可能なマルコフ決定過程：POMDP
    <h4>マルコフ過程（マルコフ連鎖)</h4>
      状態Sと行為Aと遷移確率Pと報酬Rと(割引率γ)の組 <lt> S, A, P, R, γ <gt>

    </div></div>
      
  <h3>Q学習</h3>
    <div class="hidden_box">
    <label for="label-q-learning">[+]</label>
    <input type="checkbox" id="label-marcov"/>
    <div class="hidden_show">
    <h4>基本</h4>
      動的で複雑な環境に対応する学習
    <h4>価値反復と方策反復</h4>
      <h5>更新反復</h5>
      <h5>価値反復</h5>

    <h4>アルゴリズム</h4>
    行動価値観数(Q, A)に基づき、時刻の行動は行動方策に従って選択されるQ(S, A)を更新

    </div></div>

<h2>データ前処理</h2>
  <h3>データ拡張・水増し</h3>
    <div class="hidden_box">
    <label for="label-data-extension">[+]</label>
    <input type="checkbox" id="label-data-extension"/>
    <div class="hidden_show">

    学習の際に必要なデータを水増しする。
    回転、平行移動、拡大・縮小、反転、アフィン変換、剪断変換、ホモグラフィ変換、色、光量変換、ノイズ追加など。
    
    <dl>
      <dt>ImageDataGenerator(keras)</dt>
      <dd>
        ランダムにデータの反転、圧縮、移動、回転などを行うことができる。
        ミニバッチでデータを作成しながら、学習することで、メモリも少なくてすむ。
      </dd>
      <dt>mixup</dt>
      <dd>データ間を線形に補間したものを使用する。この時同時にラベルも学習する。
          分類問題のときは、0でも1でもないデータができる。</dd>
    </dl>
    </div></div>

  <h3>データクレンジング</h3>
    <div class="hidden_box">
    <label for="label8-1">[+]</label>
    <input type="checkbox" id="label8-1"/>
    <div class="hidden_show">

    <h4>雑音除去</h4>
    ICAや平準化などで行うことが可能。

    <h4>平準化</h4>
    ローパスフィルタを通してスパイクを除去する。

    <h4>センタリング</h4>
    平均を0にする

    <h4>正規化：標準化</h4>
      特徴を平均0、分散1にすることで、特徴ごとのデータ分布を近づける。
      ImageDataGeneratorを使う場合は以下のようになる。
<pre> <code># ジェネレーターの生成
data_generator = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)

# 標準化
g = data_generator.flow(X_train, y_train, shuffle=False)
X_batch, y_batch = g.next() </code> </pre>
    <h4>正規化：白色化</h4>
    特徴間の相関をなくし、分散を一定にする。
<pre> <code># ジェネレーターの生成
datagen = ImageDataGenerator(featurewise_center=True, zca_whitening=True)

# 標準化
g = datagen.flow(X_train, y_train, shuffle=False)
X_batch, y_batch = g.next() </code> </pre>

    <dl>
      <dt>バッチ正規化</dt>
      <dd>
      ミニバッチ学習の際にバッチごとに標準化を行うこと。
      Kerasの実装は以下の通り。
<pre> <code> model.add(BatchNormalization()) </code> </pre>
      </dd>

      <dt>重み正規化</dt>
      <dd>
        入力xではなく、重み係数wを正則化(平均０分散１）
      </dd>
      <dt>層正規化</dt>
      <dd>
        層内の全ニューロンを正則化(平均０分散１）する。入力データが１でも正則化可能。
      </dd>

      <dt>主成分分析</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>特異値分解</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>ゼロ位相成分分析</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>局所的応答正規化</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>帯域コントラスト正規化</dt>
      <dd>
        Todo:内容
      </dd>
      <dt>局所的コントラスト正規化</dt>
      <dd>
        Todo:内容
      </dd>
    </dl>

    </div></div>


<h2>評価</h2>
  <h3>標準問題</h3>
    <div class="hidden_box">
    <label for="label7-1">[+]</label>
    <input type="checkbox" id="label7-1"/>
    <div class="hidden_show">

    <dl>
      <dt>MNIST(エムニスト)</dt>
      <dd>手書き数字のデータセット、28x28で１チャンネルのデータとなっている</dd>
      <dt>CIFAR-10</dt>
      <dd>10種類のオブジェクトが映った画像の10x10のデータセットの分類</dd>
      <dt>ImageNet(<a href="http://www.image-net.org">http://www.image-net.org/</a>)</dt>
      <dd>データが公開されているので登録すればダウンロード可能</dd>
      <dt>MS-COCO(<a href="http://cocodataset.org/#home">http://cocodataset.org/#home</a>)</dt>
      <dd>画像に対して５つのキャプションが与えられる。表現の多様性をチェックする</dd>    </dl>
    </div></div>
  <h3>分類の評価</h3>
    <div class="hidden_box">
    <label for="label7-2">[+]</label>
    <input type="checkbox" id="label7-2"/>
    <div class="hidden_show">
    <dl>
      <dt>正解率, 精度, accuracy</dt>
      <dd>(TP + TN) / (TP + TN + FP + FN)</dd>
      <dt>適合率, precision</dt>
      <dd>
        <div>trueのと予測した中で実際にtrueである割合</div>
        <div>(TP) / (TP + FP)
      </dd>
      <dt>再現率, 検出率, recall</dt>
      <dd>
        <div>実際にtrueの値のうち正であると予測されたもの</div>
        <div> (TP) / (TP + FN)</div>
      </dd>
      <dd>
      <dt>F値, F-measure</dt>
      <dd>
        <div>正解率と再現率のバランス</div>
        <div>(2 * precision * recall) / (precision + recall)</div>
      </dd>
    </dl>
    <dL>

    <dt>項目応答理論</dt>
    <dd>例えば、被験者の能力に対して、各テスト項目の正答確率がモデル化できるとすると、そのモデルと実際結果を比較し、それぞれの項目が妥当かどうかを確認できる</dd>
    </dl>


    </div></div>

  <h3>回帰の評価</h3>
    <div class="hidden_box">
    <label for="label-evaluation-of-regression">[+]</label>
    <input type="checkbox" id="label-evaluation-of-regression"/>
    <div class="hidden_show">
    <h4>バイアスバリアンス分解</h4>
    <dl>
      <dt>バイアス</dt>
      <dd>予測値と真値の誤差、アンダーフィッティング時に大きくなりがち</dd>
      <dt>バリアンス</dt>
      <dd>予測値と真値の分散、オーバーフィッティング時に大きくなりがち</dd>
    </dl>
    </div></div>
  <h3>NNの評価</h3>
    <div class="hidden_box">
    <label for="label7-4">[+]</label>
    <input type="checkbox" id="label7-4"/>
    <div class="hidden_show">
    <dl>
      <dt>BLEU (<a href="https://www.aclweb.org/anthology/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation </a>)</dt>
      <dd>機械翻訳の指標。過去の単語から次の単語の出現確率を算出するn-gramを改良して使用する。</dd>
      <dt>ROUGE(<a href="https://www.aclweb.org/anthology/W04-1013.pdf">ROUGE: A Package for Automatic Evaluation of Summaries </a>)</dt>
      <dd> 自動要約システムのための指標。正しい要約と自動要約システムの中のオーバーラップされた言葉の数の割合を調べる。</dd>
      <dt>METEOR(<a href="https://www.cs.cmu.edu/~alavie/papers/BanerjeeLavie2005-final.pdf">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments</a>)</dt>
      <dd> 機械翻訳の指標。ユニグラムの正確性と再現性の調和平均を元に計算される。正確性より再現性により重きを置く。</dd>
        <dt>CIDEr (<a href="https://arxiv.org/pdf/1411.5726.pdf">CIDEr: Consensus-based Image Description Evaluation</a>)</dt>
      <dd> 画像の自動キャプション付の指標。</dd>
    </dl>
    </div></div>
 
<h2>AIの応用例</h2>
  <h3>自然言語処理</h3>
    <div class="hidden_box">
    <label for="label7-3">[+]</label>
    <input type="checkbox" id="label7-3"/>
    <div class="hidden_show">

    <h4>単語埋め込みモデル word2vec</h4>
    "king" - "man" + "woman" = "Queen" <br>
    単語のベクトルを用いて、単語の足し算、引き算が可能となる。同じように文法も解ける。
    それぞれの単語が0,1の入力層が数万個で表示されていたのが、まとめてベクトルとすると、
    ベクトルが学習によって意味を表すようになってきた。
    自分以外の周りの単語を予測するスキップグラムとその逆のCBOWで学習させると中間層に意味の表層ができる。

    <h4>トピックモデル</h4>
    <dl>
      <dt>潜在的ディリクレ配分法</dt>
      <dd>トピックモデルにおいて、トピック分布にディリクレ分布を仮定し、ベイズ推定する手法。
          ある現象が起きたときに次の現象が起きる確率であるガンマ分布を全ての単語で計算し、
          確率密度関数を作成する。 適応的にパラメータが変わるノンパラメトリックモデルである。

      </dd>
    </dl>
    </div></div>
 

  <h3>画像認識</h3>
    <div class="hidden_box">
    <label for="label-image">[+]</label>
    <input type="checkbox" id="label-image"/>
    <div class="hidden_show">
    <h4>Regions with CNN features (R-CNN)</h4>
      画像に対してオーバーラップを許して何が写っているのかを示す。
      バウンディングボックスと呼ばれる画像領域を切り出して、正規化して、CNNに入れる。
      関心領域の切り出し方法は従来の方法
    <h4>fast-RCNN</h4>
      画像の切り出しを１つのネットワークで行い実時間画像処理が可能に。
    <h4>FCN</h4>
      セマンティックセグメンテーション。細かい切り出しができる
    <h4>YOLO (you lok only onece)</h4>
      バウンディングボックスの切り分けと認識が一回でできる。
    <h4>SSD (Single Shot Multibox Detector)</h4>
      バウンディングボックスの切り分けと認識が一回でできる。
    <h4> SegNet</h4>
      実時間での画像領域の細かい切り出しができるようになった。

    <h4>画像キャプション付け</h4>
        画像処理と自然言語処理を組み合わせた問題。
        <h5>NIC</h5>

    </div></div>

  <h3>音声認識</h3>
    <div class="hidden_box">
    <label for="label-sound">[+]</label>
    <input type="checkbox" id="label-sound"/>
    <div class="hidden_show">

    <h4>WaveNet</h4>
      音声認識、音声生成、テキスト読み上げ。
      delayted(スキップを伴う)学習を伴う。
      従来モデルであるparametoricモデルとconcatenativeのモデルと比べると1.5倍ぐらいの点数。

     </div></div>

  <h3>ロボティクス</h3>
    <div class="hidden_box">
    <label for="label-robotics">[+]</label>
    <input type="checkbox" id="label-robotics"/>
    <div class="hidden_show">


    <h4>Competitive Self Play (Open AI)</h4>
      報酬系だけを変えることによって、相撲だけでなく、サッカーのPKなどができるようになる。
      そのスキルを別のスキルに転移することもできる。

    <h4>Alpha Go zero</h4>
      囲碁の定石を学習させないことでより囲碁が強くなった。

    </div></div>

  <h3>ブロックチェーン</h3>
    <div class="hidden_box">
    <label for="label-blockchain">[+]</label>
    <input type="checkbox" id="label-blockchain"/>
    <div class="hidden_show">
      ブロックチェーン
    </div></div>

  <h3>異常検知</h3>
    <div class="hidden_box">
    <label for="label-failure-detection">[+]</label>
    <input type="checkbox" id="label-failure-detection"/>
    <div class="hidden_show">
      異常検知
    </div></div>



<h2>AIの注意点</h2>
  <h3>偏見への問題</h3>
    <div class="hidden_box">
    <label for="label-caution1">[+]</label>
    <input type="checkbox" id="label-caution1"/>
    <div class="hidden_show">
    黒人の女性をゴリラとして認識された例がある。学習データが白人に偏ってしまっている。
    取り込められるデータが偏ると、出力が偏ってしまう。
    </div></div>
  <h3>ブラックボックス</h3>
    <div class="hidden_box">
    <label for="label-caution2">[+]</label>
    <input type="checkbox" id="label-caution2"/>
    <div class="hidden_show">
    パラメータが改ざんされてもわからない、危険な使い方をしていてもわからない可能性がある。
    個人の勉強と専門家を用意するべき。
    </div></div>
  <h3>fooling CNN</h3>
    <div class="hidden_box">
    <label for="label-caution3">[+]</label>
    <input type="checkbox" id="label-caution3"/>
    <div class="hidden_show">
  　画像を少しだけ変えると、認識が変わる例がある。
  　我々の認識とDNNの認識方法は異なっている。
  <h4>One Pixcel Attack</h4>
    元画像に１画素だけ異なる所を付け加えると認識が変わる。
    </div></div>



<h2>その外</h2>
    <div class="hidden_box">
    <label for="label-sonohoka">[+]</label>
    <input type="checkbox" id="label-sonohoka"/>
    <div class="hidden_show">

  <dl>
    <dt>勾配降下法</dt>
    <dd><a href="math/index.html">数学-最適化問題</a>へ移動</dd>

    <dt>Empirical Risk Minimization(ERM, 経験損失最小化)</dt>
    <dd>損失関数とデータについて求めた経験損失を最小化するようにモデルを選ぶ学習の基準</dd>

    <dt>Competitive Learning(競合学習)</dt>
    <dd>
    教師なし学習で頻繁に行われる学習で、最も入力データに反応したニューロンのみ更新したりするようなニューロン同士で競わせるような学習.</dd>
    <dt>転移学習</dt>
    <dd>
      学習済みのモデルを使って新たなモデルの学習を行うこと。VGG16などがある。
    </dd>
    <dt>NIC</dt>
    <dd>
    写真から何をしているのかを言語化する。
    </dd>
    <dt>識別モデル</dt>
    <dd>
      Xをデータ、Yをラベル(従属変数)とするとXとYの関係を直接記述する。
    </dd>

    <dt>生成モデル</dt>
    <dd>
    クラスに対する条件付き分布をもとめることで、クラスに属するデータがどういうものであるかを知ることができる。
    ここから逆算して、入力に人工的なデータを作り出すことができる。
    ベイズモデルは生成モデルであり、代表的なものとしてはナイーブベイズモデルがある。
    <dt>TPU</dt>
    <dd>

    </dd>

    <dt>sota</dt>
    <dd>
      その時の最高性能が出せるアルゴリズム
    </dd>
    <dt>minimax法</dt>
    <dd>ゲーム木において、相手は自分にとって最悪手、自分は最善手を選ぶとして最善手を算出する方法</dd>
    <dt>αβ法</dt>
    <dd>minimax法でβカット(自分の手を計算する時に、現在の候補より評価値が低い手のノードを探索しないこと)とαカット(相手の手を計算するときに、現在の候補より評価値の高いノードを探索しないこと)を行う手法</dd>
    <dt>AIC、赤池情報量基準</dt>
    <dd>情報量基準(パラメータで記述されたモデルのクラスからモデルを選択する基準)の１つ。 T*log(s^2)+2K、ここでTは標本の大きさ、s^2はモデル誤差校の分散推定量、Kはモデルに含まれる係数の数</dd>
    <dt>BIC、ベイジアン情報量基準</dt>
    <dd>情報量基準(パラメータで記述されたモデルのクラスからモデルを選択する基準)の１つ。 T*log(s^2)+K*log(T)、 ここでTは標本の大きさ、s^2はモデル誤差校の分散推定量、Kはモデルに含まれる係数の数</dd>


  </dl>
  </div></div>

<h2>参考文献、サイト</h2>
<div>
  <dl>
    <dt> <cite><a href="https://daihen.aidemy.jp/">"Aidemy"</dt>
    <dd> AIの通信教育。ビデオ講座や実際にコードを書くプログラム講座など</dd>
    <dt><cite><a href="http://bookclub.kodansha.co.jp/product?item=0000147655">岩田 具治."トピックモデル、機械学習プロフェッショナルシリーズ".2018,講談社</a> </cite></dt>
    <dd>  </dd>

  </dl>
</div>

<div class = "end_of_page"></div>

</main>
</body>
</html>
