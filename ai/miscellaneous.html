<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai - miscellaneous</title>
<base href="../" />

<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
      tex: {
        macros: {
        x: "{\\times}",
        bm: ["{\\boldsymbol{#1}}",1],
        dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
        },
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true,
        tags: "ams",
        autoload: {
          color: [],
          colorV2: ['color']
        },
        packages: {'[+]': ['noerrors']}
      },
      chtml: {
        matchFontHeight: false,
        displayAlign: "left",
        displayIndent: "2em"
      },
      options: {
        renderActions: {
          /* add a new named action to render <script type="math/tex"> */
          find_script_mathtex: [10, function (doc) {
            for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            }
          }, '']
        }
      },
      loader: {
        load: ['[tex]/noerrors']
      }
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle">
      - AI
      - miscellaneous.html
    </span>
  </div>
</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日 : ' + document.lastModified);
</script>
<!--...........................更新内容............................-->
：
</div>

</div>
<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h2>その外(未整理)</h2>
  <h3>self organizing map <span class="small"> :  SOM, 自己組織化</span></h3>
    <div class="hidden_box">
    <label for="label-som">[+]　　　</label>
    <input type="checkbox" id="label-som"/>
    <div class="hidden_show">

    <dl>
      <dt>マルスバーグの自己組織化</dt>
      <dd>
        Todo : 内容
      </dd>
      <dt>コホネンの自己組織化</dt>
      <dd>
        ランダムベクトルからなる行列を用意する。入力ノード群を用意し、
        そのノードに一番近い点とそのノードの隣接点に暴露することを繰り返すことで分類ができる。
       (結果的に入力ノードが消える場合もある）
      </dd>
      <dt>リンスカーの受容野形成の自己組織化</dt>
      <dd>
        Todo : 内容
      </dd>
      <dt>オジャのSOMの自己組織化</dt>
      <dd>
        Todo : 内容
      </dd>
    </dl>
    </div></div>

  <h3>その他用語</h3>
    <div class="hidden_box">
    <label for="label-sonohoka">[+]　　　</label>
    <input type="checkbox" id="label-sonohoka"/>
    <div class="hidden_show">

  <dl>
    <dt>怠惰学習</dt>
    <dd>事前にモデルを構築しない学習法</dd>
    <dt>勾配降下法</dt>
    <dd><a href="math/index.html">数学-最適化問題</a>へ移動</dd>

    <dt>Empirical Risk Minimization(ERM, 経験損失最小化)</dt>
   <dd>損失関数とデータについて求めた経験損失を最小化するようにモデルを選ぶ学習の基準</dd>

    <dt>Competitive Learning(競合学習)</dt>
    <dd>
    教師なし学習で頻繁に行われる学習で、最も入力データに反応したニューロンのみ更新したりするようなニューロン同士で競わせるような学習.</dd>
    <dt>NIC</dt>
    <dd>
    写真から何をしているのかを言語化する。
    </dd>
    <dt>識別モデル</dt>
    <dd>
      Xをデータ、Yをラベル(従属変数)とするとXとYの関係を直接記述する。
    </dd>

    <dt>生成モデル</dt>
    <dd>
    クラスに対する条件付き分布をもとめることで、クラスに属するデータがどういうものであるかを知ることができる。
    ここから逆算して、入力に人工的なデータを作り出すことができる。
    ベイズモデルは生成モデルであり、代表的なものとしてはナイーブベイズモデルがある。
    <dt>TPU</dt>
    <dd>

    </dd>

   <dt>minimax法</dt>
    <dd>ゲーム木において、相手は自分にとって最悪手、自分は最善手を選ぶとして最善手を算出する方法</dd>
    <dt>αβ法</dt>
    <dd>minimax法でβカット(自分の手を計算する時に、現在の候補より評価値が低い手のノードを探索しないこと)とαカット(相手の手を計算するときに、現在の候補より評価値の高いノードを探索しないこと)を行う手法</dd>
    <dt>AIC、赤池情報量基準</dt>
    <dd>情報量基準(パラメータで記述されたモデルのクラスからモデルを選択する基準)の１つ。 T*log(s^2)+2K、ここでTは標本の大きさ、s^2はモデル誤差校の分散推定量、Kはモデルに含まれる係数の数</dd>
    <dt>BIC、ベイジアン情報量基準</dt>
    <dd>情報量基準(パラメータで記述されたモデルのクラスからモデルを選択する基準)の１つ。 T*log(s^2)+K*log(T)、 ここでTは標本の大きさ、s^2はモデル誤差校の分散推定量、Kはモデルに含まれる係数の数</dd>

    <dt>ImageDataGenerator(keras)</dt>
    <dd>
      ランダムにデータの反転、圧縮、移動、回転などを行うことができる。
      ミニバッチでデータを作成しながら、学習することで、メモリも少なくてすむ。
    </dd>
  </dl>
  </div></div>

<h3>参考文献、サイト</h3>
<div>
  <ol>
    <li><cite><a href="https : //www.shoeisha.co.jp/book/detail/9784798157559">一般社団法人日本ディープラーニング協会監修, 浅川 伸一, 江間 有沙, 工藤 郁子, 巣龍 悠輔, 瀬谷 啓介, 松井 孝之, 松尾 豊."深層学習教書 ディープラーニング G検定（ジェネラリスト） 公式テキスト", 2018, 翔泳社</li>
    <li><cite><a href="https : //www.shoeisha.co.jp/book/detail/9784798157559">岡谷 貴之."深層学習", 2015, 講談社</li>
    <li><cite><a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B">"マルコフ決定過程", wikipedia</a>
    <li><cite><a href="http://may46onez.hatenablog.com/entry/2016/01/08/142843">gco(id:may46onez)."theanoでLocal Response Normalization(LRN)を使う (備忘録とか日常とか)",2016, Hatena Blog</li>
    <li><cite><a href="https://www.aaai.org/Papers/KDD/1996/KDD96-014.pdf">Usama Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, "Knowledge Discovery and Data Mining: Towards a Unifying Framework",1996, KDD-96 Proceedings</li>
    <li><cite><a href="https://bellcurve.jp/statistics/glossary/1233.html">BellCurve, "ピアソンの積率相関係数", 統計WEB</a>
    <li><cite><a href="https : //daihen.aidemy.jp/">"Aidemy"</li>
  </ol>
</div>

<div class = "end_of_page_margin"></div>
<div class = "end_of_page">
<a class="prev" href="ai/cautions.html" >前：人工知能使用上の注意</a>
<a class="upper" href="index.html" >上：ホーム</a>
<a class="next" href="index.html">次：ホーム</a>
</div>



</main>
</body>
</html>
