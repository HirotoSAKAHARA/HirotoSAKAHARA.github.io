<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai</title>
<base href="../" />

<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
      tex: {
        macros: {
        x: "{\\times}",
        bm: ["{\\boldsymbol{#1}}",1],
        dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
        },
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true,
        tags: "ams",
        autoload: {
          color: [],
          colorV2: ['color']
        },
        packages: {'[+]': ['noerrors']}
      },
      chtml: {
        matchFontHeight: false,
        displayAlign: "left",
        displayIndent: "2em"
      },
      options: {
        renderActions: {
          /* add a new named action to render <script type="math/tex"> */
          find_script_mathtex: [10, function (doc) {
            for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            }
          }, '']
        }
      },
      loader: {
        load: ['[tex]/noerrors']
      }
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle">
      - AI
      - basics
    </span>
  </div>
</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日 : ' + document.lastModified);
</script>
<!--...........................更新内容............................-->
：
</div>
</div>

<!--*********************************本文*********************************-->
<div class=site-header-margin>
</div>
<h2>人工知能の基本</h2>
  <h3>人工知能とは</h3>
    <div class="hidden_box">
    <label for="label_about_ai">[+]　　　</label>
    <input type="checkbox" id="label_about_ai"/>
    <div class="hidden_show">
    <h4>定義</h4>
      専門家の間ですら共有されている定義はない。
      しかし、<q>「人工知能」が、推論、認識、判断など、人間と同じ知的な処理能力を持つ機械（情報処理システム）であるという点については、
      大多数の研究者の意見は一致しているといってもよい」</q>[1]　

    <h4>人工知能の種類</h4>
      人工知能には様々な手法が含まれる。
      機械学習と呼ばれる手法は大量のデータによって予測を行う人工知能の一種であり、
      深層学習はその中でもニューラルネットと呼ばれるアルゴリズムの特殊なものである。
    <div>
      <img src="out\ai\kind_of_ai.png" alt="aiの種類"/>
    </div>

    <h4>機械学習とデータマイニング</h4>
      大量のデータを利用して特徴を見つけ出す手法には、機械学習とデータマイニングがある。
      これらは使用する技法は同じだが目的が異なる。
      機械学習の目的は発見したデータの特徴からあるデータに付随するデータの値を予測することであり、
      データマイニング目的は未知のデータの特徴を発見することである。
      データマイニングは英語ではknowledge-discovery in databasesの頭文字をとってKDDとも呼ばれる。
    </div></div>

  <h3>教師の有無による分類</h3>
    <div class="hidden_box">
    <label for="label_classify_by_teacher">[+]　　　</label>
    <input type="checkbox" id="label_classify_by_teacher"/>
    <div class="hidden_show">
      大きく分けて、教師あり学習、教師なし学習、強化学習にわけられる。教師データの解釈の仕方で分類が変わりうる。

    <h4>supervised learning<span class="small"> : 教師あり学習</span></h4>
      事前に与えられたデータをいわば例題とみなして、それをガイドに学習を行う。
      学習後は、入力に対して尤度が最大となる出力を求める。

    <h4>unsuperviesd learning<span class="small"> : 教師なし学習</span></h4>
      学習データを教えることによって、それぞれのデータの分類やデータ群の特徴の抽出を行う。

    <h4>reinforcement learning<span class="small"> : 強化学習</span></h4>
      行動の結果が行動の後にスカラ値の報酬として与えられる。
      報酬は即時に与えられるとは限らず、報酬は行動の改善の方法を与えない。
    </div></div>

  <h3>人工知能により解決するタスクの種類</h3>
    <div class="hidden_box">
    <label for="label_classify_by_task">[+]　　　</label>
    <input type="checkbox" id="label_classify_by_task"/>
    <div class="hidden_show">
      
    <h4>classification <span class="small"> : 分類</span></h4>
      教師あり学習の一種で、二値分類と多クラス分類がある。
      <h5>二値分類</h5>
      <q>入力\(\boldsymbol{x}\)を内容に応じて２種類に区別する問題</q>[2]
      <h5>多クラス分類</h5>
      <q>入力\(\boldsymbol{x}\)を内容に応じて有限個のクラスに分類する問題</q>[2]

    <h4>regression<span class="small"> : 回帰</span></h4>
      教師あり学習の一種で、訓練データをよく再現するような関数を定める問題。連続値をとる関数を主な対象とする。
      <h5>線形回帰</h5>
      \(z = w_0 + w_1u_1 + \cdots + w_uu_n + e\) のような、変数\(\boldsymbol{u}\)の線型結合で示される関数の係数\(\boldsymbol{w}\)を求める問題。
      多項回帰のように、変数自体は非線形の関数で表されても構わない。
      以下に分類される。
      <dl>
        <dt>単回帰</dt>
        <dd>変数が１つの１次式(\( z = wu + w_0 \) )の回帰。導出される1次式を回帰直線と呼ぶ。</dd>
        <dt>多項回帰</dt>
        <dd>変数が１つのn次式(\( y = w_1u + w_2u^2 + \cdot + w_nu^n + w_0 \))の回帰</dd>
        <dt>重回帰</dt>
        <dd>変数が複数ある式(\( y = w_1u_1 + w_2u_2 + \cdot + w_nu_n + w_0 \))の回帰</dd>
      </dl>
      <h5>非線形回帰</h5>
        観測から得られたデータがモデルパラメータの非線形結合であり、1つ以上の独立した変数に依存する関数によってモデル化される。

    <h4>clustering<span class="small"> : クラスタリング</span></h4>
      教師なし学習の一種で、ラベルのないデータ群を複数に分る問題。

    <h4>dimensionality reduction<span class="small"> : 次元削減(次元圧縮)</span></h4>
      教師なし学習の一種で、
      データの次元数を減らすこと。 計算の効率化を行ったり、データ群の特徴をつかむことが目標。
      線形の場合はデータ\(\boldsymbol{Y}\)を低次元の\(\boldsymbol{W}\)と
      \( \boldsymbol{X}\)を用いて\( \boldsymbol{Y} \simeq \boldsymbol{W^TX}\)と表せるが、
      非線形の次元削減手法も存在する。
      
    <h4>reinforcement learning<span class="small"> : 強化学習</span></h4>  
      各時刻に置ける最適な意思決定のルールを目的とする。
      報酬の期待値を最大するような逐次的意思決定ルール(ポリシー)を学習する。
    <h4>Recommendation <span class="small"> : 推薦</span></h4>
      情報フィルタリング技法の一種で、特定ユーザーが興味を持つと思われる情報を提示するもの。 

    <h4>bayesian optimization<span class="small"> : ベイズ最適化</span></h4>  
      教師なし学習の一種で、あるデータの存在領域を学習により狭めていく。

    </div></div>
    
    <h3>機械学習の基礎 <span class="small">(教師あり学習、教師なし学習、データマイニング)</span></h3>  
      <div class="hidden_box">
      <label for="label_procedure">[+]　　　</label>
      <input type="checkbox" id="label_procedure"/>
      <div class="hidden_show">
      <h4>教師あり学習、教師なし学習の手順</h4>
        教師あり学習、教師なし学習の学習の手順を示す。用語については次節で示す。
        データは学習に利用する訓練データと検証に利用する検証データ、テストデータに分割するが、
        これは、モデルが学習のし過ぎによりオーバーフィッティング状態となり、
        汎化性能が下がっていないことを確認するためである。
      <div>
        <img src="out\ai\learning_procedure.png" alt="学習手順"/>
      </div>

      <h4>CRISP-DM<span class="small"> : cross industry standard process for data mining-DM</span></h4>
        <div>
        CRISP-DMコンソーシアムによって提唱されたデータ分析プロジェクトのプロセスモデル。
        </div>
        
        <div>
        1.ビジネス理解で課題を明確にし、2.データ理解でデータを取得、3.データ準備でデータを整形し、4.モデリングで分析、
        その結果を5.評価して、6.適用、あるいは、もう一度サイクルを回し、考え直す。というやり方。
        </div>
        <img src="out\ai\CRISP-DM.png" alt="CRISP-DM"/>
    
      <h4>KDD<span class="small"> : Knowledge Discovery in Databases</span></h4>
        <div>
        データマイニングにより、データから知識を探索するためのプロセスモデル。CRISP-DMと比較し、よりデータ分析部分にフォーカスしており、以下の手順ですすめる。[6]
        </div>
        <div>
      <ol>
        <li> アプリケーションドメインの理解を構築し、消費者の視点でkddプロセスの目標を決定する。</li>
        <li> 発見がなされるデータ・セットを選択し、または変数やデータサンプルのサブセットに注目し、目的データ・セットを構築する。</li>
        <li> 適切なノイズ除去や時系列情報や変化を利用した欠損データ対策などのデータクレンジングと前処理を行う。</li>
        <li> タスクの目標に依存するデータの特徴を見つけるために、次元削減やデータ変換をし、変数の削減あるいはデータの不変量を見つける。</li>
        <li> kddプロセスの目標を特定のデータマイニング手法に合わせる。例えば、要約、分類、回帰、クラスタリングなど。</li>
        <li> データのパターンを探索するデータマイニングアルゴリズムの選択する。</li>
        <li> データマイニングを行う。</li>
        <li> マイニングされたパターンの解釈を行う。特に、モデルパターンの可視化や得られたパターンから与えられたデータの可視化を含む。</li>
        <li> 発見した知識を他のシステムと統合するか、あるいは単に興味ある人々のために文書化する。</li>
      </ol>

      <img src="out\ai\kdd.png" alt="kdd" width="100%"/>
      </div>  

      <h4>用語</h4>
        <h5>data ingestion<span class="small"> : データインジェスチョン</span></h5>
          csv, excel, xml, 紙, 音声などの様々な媒体、形式で保存されている様々な形式のデータを
          同じ形式で利用できるよう加工すること。通常はデータベースに格納する。

        <h5>data cleansing<span class="small"> : データクレンジング</span></h5>
          データを検査し、不正なデータや、同じデータ、文法異常のデータなどを修正、破棄することで、
          データの質（有効性、正確さ、完全さ、一貫性、統一性）を上げること。

        <h5>training dataset<span class="small"> : 訓練データ</span></h5>
          モデルを適合するためのデータのサンプル

        <h5>validation dataset<span class="small"> : 検証データ</span></h5>
          訓練データで適合したモデルを評価し、
          チューニングの要否やチューニングの方向性を決めるためのデータのサンプル。
          
        <h5>test dataset<span class="small"> : テストデータ</span></h5>
          訓練データで適合され、検証データを使いチューニングされた
          最終的なモデルの評価のために使用されるデータのサンプル。

        <h5>generalization performance<span class="small"> : 汎化性能</span></h5>
          テストデータなど、未学習のデータでの性能。

        <h5>overfitting <span class="small"> : 過学習, 過剰適合</span></h5>
          訓練データを学習させすぎた結果、訓練データの特徴のみに特化しすぎ、汎化性能が低くなってしまうこと。

        <h5>underfitting <span class="small"> : 未学習</span></h5>
          学習が足りず、訓練データのみならず、テストデータでも性能が出ないこと。


      </div></div>

    <h3>機械学習の基礎 <span class="small">(強化学習)</span></h3>  
      <div class="hidden_box">
      <label for="label_reinforcement_learning">[+]　　　</label>
      <input type="checkbox" id="label_reinforcement_learning"/>
      <div class="hidden_show">
      <h4>概要</h4>
        エージェントが行動し、行動によって環境が変化し、
        環境から状態と報酬が与えられるようなシナリオで、
        累積報酬の最大化を達成できるようなポリシーを学習することを目的とする。
        <div>
          <img src="out\ai\reinforcement_learning.png" alt="学習手順"/>
        </div>
      <h4>特徴</h4>
        エージェントが探索し、探索の後で報酬が与えられるということはほかの学習と大きく異なる。
        行動により環境が変化するために、探索と活用のトレードオフが発生する。
  
      <h4>MDP <span class="small">: Marcov Decision Process、マルコフ決定過程</span></h4>
        状態の組と、行動の組、初期状態が各状態での遷移確率とある状態からある状態に遷移したときの報酬の期待値が定義されている状態で、エージェントがとるポリシーを決定する。強化学習は、マルコフ決定過程におけるポリシーの最適化問題と言える。(下図はwikipediaの図：<a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B#/media/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:Markov_Decision_Process_example.png">３つの状態と２つの行動を持つ簡単なMDPの例</a>をplantumlで書いたもの)
        <div>
          <img src="out\ai\marcov_decision_process.png" alt="マルコフ決定過程"/>
        </div>

      <h4>用語</h4>
        <h5>エージェント</h5>
        制御器や意思決定者</dd>

        <h5>環境</h5>
        制御対称システム</dd>

        <h5>行動</h5>
        エージェントが環境を変化させる行為

        <h5>報酬</h5>
        その行動が良かったか悪かったかを示すスカラ値。行動への具体的なヒントにならない。
        行動の行った後、遅れて示される。

        <h5>状態</h5> 
        環境が現在どうなっているかを表すパラメータ。

        <h5>ポリシー</h5> 
        報酬の期待値を最大にするような逐次的意思決定ルール。

        <h5>状態価値関数</h5> 
        ある状態から、あるポリシーで行動を続けた時の報酬の総和。

        <h5>行動価値関数</h5> 
        ある状態から、ある行動をとった後、あるポリシーで行動を続けた時の報酬の総和。

        <h5>価値関数</h5>
        あるポリシーを行ったときの、報酬の期待値。 状態価値関数vと行動価値関数qがある。

        <h5>最適価値関数</h5>
        価値関数の中で最大値となるもの。一般にはベルマン方程式となり、計算するのは非常に難しい。

        <h5>収益</h5>
        即時報酬＋Σ(割引率*未来の報酬)。

        <h5>TD学習</h5>
        モンテカルロ法と動的計画法を合わせた方法で、経験的に学習を行いつつ、
        途中で評価値を更新していく学習手法。Q学習やActor-Critic法、TD(\(\lambda\))法はこの学習法の一つ。

        <h5>探索と利用のジレンマ</h5>
        ある行動が最適かどうかは別の行動をしないとわからないが、最良の行動と決定している別の行動ばかりしていると良い行動を選べない。

    </div></div>

    <h3>その他基本的なトピック</h3>  
      <div class="hidden_box">
      <label for="label_basic_topics">[+]　　　</label>
      <input type="checkbox" id="label_basic_topics"/>
      <div class="hidden_show">

      <h4>基本用語</h4>
       <h5>sota</h5>
          あるタスクにおいて、その時の最高性能が出せるアルゴリズム

        <h5>boostrap method :<span class="small">ブートストラップ法</span></h5>
          ある限られた標本集団から母集団の性質を推定するための方法で、
          繰り返しを許してランダムにn個の標本を取得し、
          その標本から得られる推定値の分布からパラメータの確率分布や誤差を推定する方法。

        <h5>ensemble learning<span class="small"> : アンサンブル学習</span></h5>
          より良い予測性能を出すために、複数のアルゴリズムを用いること。

        <h5>bagging <spam class="small"> : バギング</spam></h5>
          訓練サンプル集合からブーストラップサンプル集合を複数作成し、
          それぞれのサンプル集合に対し独立なモデルを複数学習させ、
          すべてのモデルの予測値をもとに、最終的な予測値を決定する方法。
          モデル固有の誤差が相殺されるため、性能が安定する。

        <h5>boosting <spam class="small"> : ブースティング</spam></h5>
          一連の弱い学習機をまとめることで強い学習機を生成する機械学習のメタアルゴリズム。
          弱い学習機とは真の分類と若干の相関がある分類器で、強い学習機とは真の分類と良く相関する学習機のこと。
          複数の弱い学習機に学習させた後、学習に失敗したデータの重みづけが見直され、
          別の弱い学習機によって再学習を行う。
          難しいデータを正しく分類した学習機を重みを高め、学習機を統合する。


        <h5>階層的クラスタリング</h5>
          データの一部をクラスタリングし、クラスタリングしたクラスを一つのデータととらえ、残りのデータとともに次のクラスタリングを行う。
        <h5>非階層的クラスタリング</h5>
          すべてのデータを一気にクラスタリングする。データ量が多い場合に有効な手法。
        <h5>正例・負例</h5>
          ２クラス分類の学習用データで値が１となってるクラスを正例、値が−１あるいは０となっているクラスを負例と呼ぶ。
        
      </div></div>

<h3>参考文献、サイト</h3>
<div>
  <ol>
    <li><cite><a href="https : //www.shoeisha.co.jp/book/detail/9784798157559">一般社団法人日本ディープラーニング協会監修, 浅川 伸一, 江間 有沙, 工藤 郁子, 巣龍 悠輔, 瀬谷 啓介, 松井 孝之, 松尾 豊."深層学習教書 ディープラーニング G検定（ジェネラリスト） 公式テキスト", 2018, 翔泳社</li>
    <li><cite><a href="https : //www.shoeisha.co.jp/book/detail/9784798157559">岡谷 貴之."深層学習", 2015, 講談社</li>
    <li><cite><a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B">"マルコフ決定過程", wikipedia</a>
    <li><cite><a href="http://may46onez.hatenablog.com/entry/2016/01/08/142843">gco(id:may46onez)."theanoでLocal Response Normalization(LRN)を使う (備忘録とか日常とか)",2016, Hatena Blog</li>
    <li><cite><a href="https://www.aaai.org/Papers/KDD/1996/KDD96-014.pdf">Usama Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, "Knowledge Discovery and Data Mining: Towards a Unifying Framework",1996, KDD-96 Proceedings</li>
    <li><cite><a href="https://bellcurve.jp/statistics/glossary/1233.html">BellCurve, "ピアソンの積率相関係数", 統計WEB</a>
    <li><cite><a href="https : //daihen.aidemy.jp/">"Aidemy"</li>
  </ol>
</div>

<div class = "end_of_page_margin"></div>
<div class = "end_of_page">
<a class="prev" href="index.html" >前：ホーム</a>
<a class="upper" href="index.html" >上：ホーム</a>
<a class="next" href="ai/preprocessing.html">次：データ前処理の手法</a>
</div>


</main>
</body>
</html>
