<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - ai - generative model</title>
<base href="../" />


<link rel="stylesheet" href="style.css">
<!-- 数式を使う宣言-->
<script>
  window.MathJax = {
    tex: {
      macros: {
      x: "{\\times}",
      bm: ["{\\boldsymbol{#1}}",1],
      dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
      },
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true,
      tags: "ams",
      autoload: {
        color: [],
        colorV2: ['color']
      },
      packages: {'[+]': ['noerrors']}
    },
    chtml: {
      matchFontHeight: false,
      displayAlign: "left",
      displayIndent: "2em"
    },
    options: {
      renderActions: {
        /* add a new named action to render <script type="math/tex"> */
        find_script_mathtex: [10, function (doc) {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = {node: text, delim: '', n: 0};
            math.end = {node: text, delim: '', n: 0};
            doc.math.push(math);
          }
        }, '']
      }
    },
    loader: {
      load: ['[tex]/noerrors']
    }
  };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>

</head>

<body>
<main>

<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle">
      - AI 
      - generative model
    </span>
  </div>
</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日:' + document.lastModified);
</script>
：
</div>
</div>

<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h2>生成モデル</h2>
  <h3>evidence of lower bound (elbo, 変分下限)</h3>

  <h3>baysian nn (ベイズ流ニューラルネットワーク)</h3>

  <h3>deep generative models</h3>

  <h3>variational autoencoders (vae 変分オートエンコーダ)</h3>
    <div class="hidden_box">
    <label for="label-vae">[+]　　　</label>
    <input type="checkbox" id="label-vae"/>
    <div class="hidden_show">

    生成モデルの枠組みで自己符号化器 (autoencoders) を解釈したもので、 生成モデルで言う潜在変数を観測データの符号と見做す. すなわち、観測データから潜在変数を推定する手続きが符号化であり、その逆が復号化である.
    グラフを使って似た画像を並べて、潜在変数を解釈することができる。
    <h4> ベイズ推論 </h4>
      条件付き確率の出力から、条件を算出する。

    <h4>変分ベイズ法 (変分推論、変分近似法)</h4>
      データ(x)と未知パラメータ(z)と潜在変数(θ)の確率分布がある場合、
      KL距離(KL Divergence)の最小化を解析的手法で求めることで最適値が求まる。

    <h4>リパラメトライゼーショントリック</h4>
      x -> z -> xを求める過程でzは確率変数でなく
      真値(平均)とノイズの組み合わせだとみなして解く。
      RNNにも応用できて、中間の文章が生成できる。

    </div></div>

  <h3>generative adversarial networks (GAN =敵対ネットワーク)</h3>
  <div class="hidden_box">
    <label for="label-gan">[+]　　　</label>
    <input type="checkbox" id="label-gan"/>
    <div class="hidden_show">
    <h4>基本</h4>
      DiscrereminatorとGeneratorの2つのネットワークが競い合う。
      Generatorはノイズから画像を生成する。
      Generatorが作ったデータをDiscreminatorの入力とし、Discriminatorはデータを判断する。

    <h4>応用</h4>
      <ul>
        <li>眼鏡つき男性画像１　ー　眼鏡なし男性画像２　＋　眼鏡なし女性画像 = 眼鏡つき女性画像</li>
        <li>模型図から実画像を生成</li>
        <li>馬をシマウマに</li>
        <li>ゴッホ風、モネ風の画像生成</li>
        <li>自動着色</li>
        <li>光源を変更</li>
     </ul>

     </div></div>

  <h3>評価</h3>
    <div class="hidden_box">
    <label for="label-evaluate-vae">[+]　　　</label>
    <input type="checkbox" id="label-evaluate-vae"/>
    <div class="hidden_show">

    <h4>動的評価</h4>
      通常は訓練データとテストデータは完全に分けて評価をするが、
      文脈においては、特定の単語（人名など）と偏ったデータになりがちなので、
      テストデータでも１回だけ学習をすること。

    </div></div>

<h3>参考文献、サイト</h3>
  <dd>
  <dt> <cite><a href="https://pdfs.semanticscholar.org/8bdf/dc2c2777b395c086810c03a8cdeccc55c4db.pdf">Wolpert, D.H., Macready, W.G. "No Free Lunch Theorems for Search", Technical Report SFI-TR-95-02-010,1995, Santa Fe Institute </a></cite></dt>
  <dd>ノーフリーランチ定理</dd>
  <dt><cite><a href="http://bookclub.kodansha.co.jp/product?item=0000147653">岡谷貴之,"深層学習(機械学習プロフェッショナルシリーズ)", 2015, 講談社</a></cite></dt>
  <dd>深層学習の基礎を網羅している本。</dd>
  <dt><cite>Akiba, Takuya, Shuji Suzuki, and Keisuke Fukuda "Extremely Large Minibatch Sgd: Training Resnet-50 on Imagenet in 15 Miniutes", 2017, arXiv Preprint.</cite>
  </dt>
  <dd></dd>
  Yee Wyne Teh NIPS 2017

  <dt> [[1606.05908] Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908) 再解釈論文 (2016)</dt>
  <dd> 変分オートエンコーダを再解釈した論文</dd>

<div class = "end_of_page_margin"></div>
<div class = "end_of_page">
<a class="prev" href="ai/rnn.html" >前：畳み込みニューラルネットワーク</a>
<a class="upper" href="index.html" >上：ホーム</a>
<a class="next" href="ai/reinforcement_learning_with_dnn.html">次：深層学習による強化学習</a>
</div>

  </main>
</body>
</html>
