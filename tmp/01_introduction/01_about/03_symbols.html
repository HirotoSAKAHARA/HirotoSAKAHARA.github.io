<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>hsmemo - - introduction - about </title>
<base href="../../" />

<link rel="stylesheet" href="style.css">
<!-- 式・使う宣言-->
<script>
    window.MathJax = {
tex: {
macros: {
x: "{\\times}",
bm: ["{\\boldsymbol{#1}}",1],
dd: ["{\\frac{\\partial #1}{\\partial #2}}",2]
},
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true,
tags: "ams",
autoload: {
color: [],
colorV2: ['color']
},
packages: {'[+]': ['noerrors']}
},
chtml: {
matchFontHeight: false,
displayAlign: "left",
displayIndent: "2em"
},
options: {
renderActions: {
/* add a new named action to render <script type="math/tex"> */
find_script_mathtex: [10, function (doc) {
for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
const display = !!node.type.match(/; *mode=display/);
const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
const text = document.createTextNode('');
node.parentNode.replaceChild(text, node);
math.start = {node: text, delim: '', n: 0};
math.end = {node: text, delim: '', n: 0};
doc.math.push(math);
}
}, '']
}
},
loader: {
load: ['[tex]/noerrors']
}
    };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script">
</script>
</head>
<body>
<main>


<!--***************************ヘッダー領域****************************-->
<div class="site-header">
<div class="title_space">
  <div class="title">
    <a href="index.html">hsmemo</a>
    <span class="subtitle"> : はじめに - このサイトについて</span>
  </div>

</div>

<div class="last_modified">
<script type="text/javascript">
   document.write('最終更新日 : ' + document.lastModified);
</script>
<!--...........................更新内容............................-->
：強化学習に関する定義を追加
</div>
</div>

<div class=site-header-margin> </div>
<!--*********************************本文*********************************-->
<h1>数学記号</h1>
    <h2>概要</h2>
        <div><div class="hidden_show">
        基本的にはwikipediaの書き方[1]を使用しています。ISO80000-2がベースになっているはずです。
        また、上記にない略称由来の関数はローマン体で書くことにします。
        例えば、KLダイバージェンスは\(\mathrm{KL}(X, Y)\)と書くことにします。
        強化学習関連に関しては、上記と矛盾がない限り、「強化学習][2]で使用されている記法に習います。

        </div></div>
    <h2>数学記号</h2>
        <div><div class="hidden_show">
        <h3>式</h3>
         <dl>
            <dt>定義する</dt><dd>\(\colon=\)</dd>
            <dt>大体等しい</dt><dd>\(\approx\)</dd>
            <dt>比例する</dt><dd>\(\propto\)</dd> 
         </dl>
        <h3>変数</h3>
         <dl>
             <dt>変数</dt><dd>\(x\)</dd>
            <dt>確率変数</dt><dd>\(X\)</dd>
            <dt>ベクトル</dt><dd>\(\bm{x}\)</dd>
            <dt>行列</dt><dd>\(\bm{X}\)</dd>
            <dt>時刻、あるいは時間ステップ\(t\)における変数、確率変数、ベクトル、行列</dt><dd>\(x_t, X_t, \bm{x}_t, \bm{X}_t\)</dd>
            <dt>転置行列</dt><dd>\(\bm{X}^\top\)</dd>
            <dt>全要素が1であるサイズ\(m\times n (m, n \in \mathbb{N})\)の行列</dt><dd>\(\bm{1}_{m, n}\)</dd>
            <dt>全要素が0であるサイズ\(m\times n (m, n \in \mathbb{N})\)の行列</dt><dd>\(\bm{0}_{m, n}\)</dd>
            <dt>第\(m\)要素が1であるサイズ\(n\)の縦ベクトル</dt><dd>\(e^n_m\)</dd>
            <dt>\(m\)次の単位行列</dt><dd>\(\bm{I}_m\)</dd>
            <dt>事象\(B\)が真なら1, そうでないなら0を出力する指示関数</dt><dd>\(\mathbb{I}_{\{B\}}\)</dd>
         </dl>

        <h3>集合</h3>
        <dl>
             <dt>n個のベクトル\(\bm{x_1}, \ldots, \bm{x_n}\)の集合</dt><dd> \(X \colon= \{\bm{x_1}, \ldots, \bm{x_n}\} \)</dd>
            <dt>母集団（の分布）、訓練データ</dt><dd>\(\mathcal{D}\)</dd>
            <dt>0を含まない自然数の集合</dt><dd>\(\mathbb{N}\)</dd>
            <dt>0を含む自然数の集合</dt><dd>\(\mathbb{N}_0\)</dd> 
            <dt>実数集合</dt><dd>\(\mathbb{R}\)</dd>
            <dt>拡大実数集合</dt><dd>\(\mathbb{\bar{R}} \;\; \colon=\mathbb{R} \cup \{-\infty, +\infty\}\)</dd>
            <dt>定義域\(\mathcal{X}\), 閾値\(\mathbb{R}\)の関数の集合</dt><dd>\(\mathbb{R}^{\mathcal{X}} \;\; \colon= \{ f \colon \mathcal{X} \rightarrow \mathbb{R}\}\)</dd>
            <dt>n次の実数集合</dt><dd>\(\mathbb{R}^n\)</dd> 
            <dt>ゼロ以上の実数の集合</dt><dd>\(\mathbb{R}_{\ge 0}\)</dd>
            <dt>条件\(P(x)\)を満たす\(x\)からなる集合\(X\)</dt><dd>\(X \colon= \{x | P(x)\}\)</dd>
            <dt>条件\(P(x)\)、\(Q(x)\)を満たす集合X</dt><dd>\(X \colon= \{x | P(x) \land Q(x)\}\)</dd>
            <dt>条件\(P(x)\)、\(x \in \mathcal{X}\)を満たす集合X</dt><dd>\(X \colon= \{x | P(x) \land x \in \mathcal{X}\}\)、 あるいは \(X = \{x \in \mathcal{X} | P(x)\}\)</dd>
        </dl>
        <h3>確率</h3>
        <dl>
             <dt>\(x\)の期待値</dt><dd>\(\bm{E}(x)\)</dd>
            <dt>確率分布\(p(x)\)の時の\(x\)の期待値</dt><dd>\(\bm{E}(x|p(x))\)</dd>
            <dt>確率分布\(p(x)\)の時の関数\(f(x)\)の期待値</dt><dd>\(\bm{E}(f(x)|p(x))\)</dd>
            <dt>確率変数\(X\)の分散</dt><dd>\(\bm{V}(X)\)</dd>
            <dt>確率変数\(X, Y\)の共分散</dt><dd>\(\sigma(X,Y)\)</dd> 
        </dl>

        <h3>その他</h3>
        <dl>
             <dt>集合\(X\)の中の最大値</dt><dd>\(\max(X)\)</dd>
            <dt>集合\(X\)の中の最小値</dt><dd>\(\min(X)\)</dd>
            <dt>式\(f_1(x), \ldots, f_n(x)\)の中の最大値</dt><dd>\(\max(f_1(x), \ldots, f_n(x))\)</dd>
            <dt>式\(f_1(x), \ldots, f_n(x)\)の中の最小値</dt><dd>\(\min(f_1(x), \ldots, f_n(x))\)</dd>
            <dt>式\(f(x)\)を最大化する</dt><dd>\({\operatorname{maximize}} \;\;f(x)\)</dd>
            <dt>式\(f(x)\)を最小化する</dt><dd>\({\operatorname{minimize}} \;\;f(x)\)</dd>
            <dt>制約条件</dt><dd>\(\text{subject to}\)</dd> 
            <dt>定義域\(A\)を終域\(B\)に移す関数\(f\)</dt><dd>\(f \colon A \rightarrow B\)</dd>
        </dl>

        </div></div>
    <h2>優先的に使う記号</h2>
        <div><div class="hidden_show">
        <dl>
            <dt>入力</dt><dd>\(u, \bm{u}, \bm{U}\)</dd>
            <dt>内部変数</dt><dd>\(x, \bm{x}, \bm{X}\)</dd>
            <dt>(ネットワークの)係数</dt><dd>\(w, \bm{w}, \bm{W}\)</dd>
            <dt>出力</dt><dd>\(z, \bm{z}, \bm{Z}\)</dd>
            <dt>共分散行列</dt><dd>\(\Sigma\)</dd>
        </dl>
        <h3>ネットワーク</h3>
        <dl>
            <dt>頂点</dt><dd>\(V\)</dd>
            <dt>辺</dt><dd>\(E\)</dd>
            <dt>頂点数</dt><dd>\(|V|\)</dd>
            <dt>辺数</dt><dd>\(|E|\)</dd>
        </dl>
        <h3>強化学習</h3>
        <dl>
        <dt>状態集合</dt><dd>\(\mathcal{S}\)</dd>
        <dt>行動集合</dt><dd>\(\mathcal{A}\)</dd>
        <dt>報酬集合</dt><dd>\(\mathcal{R} \;\; \colon= \{r \in \mathbb{R} \;\;| \;\; r = g(s, a), \exists (s, a) \in \mathcal{S} \times \mathcal{A}\}\), ここで\(g(s, a)\)は報酬関数(後述)</dd>
        <dt>現在の状態の確率変数</dt><dd>\(S\)</dd>
        <dt>現在の状態の実現値</dt><dd>\(s\)</dd>
        <dt>1ステップ後の状態の確率変数</dt><dd>\(S'\)</dd>
        <dt>1ステップ後の状態の実現値</dt><dd>\(s'\)</dd>
        <dt>時間ステップtの状態の確率変数</dt><dd>\(s_t\)</dd>
        <dt>時間ステップtの状態の実現値</dt><dd>\(s_t\)</dd>
        <dt>時間ステップtの行動の確率変数</dt><dd>\(A_t\)</dd>
        <dt>時間ステップtの行動の実現値</dt><dd>\(a_t\)</dd> 
        <dt>時間ステップtの報酬の確率変数</dt><dd>\(R_t\)</dd>
        <dt>時間ステップtの報酬の実現値</dt><dd>\(r_t\)</dd>  
        <dt>初期状態確率</dt><dd>\(p_{s_0} \;\; \colon \mathcal{S} \rightarrow [0,1] \;\; | \;\; \sum_{s \in \mathcal{S}}p_{s_0}(s) = 1 \)</dd>
        <dt>状態遷移確率</dt><dd>\(p_T \; \colon \; \mathcal{S} \times \mathcal{A} \times \mathcal{S} \rightarrow [0, 1] \;\; | \;\; \sum_{s' \in \mathcal{S}} p_T(s'|s, a) = 1, \forall(s, a) \in \mathcal{S} \times \mathcal{A} \)</dd>
        <dt>報酬関数</dt><dd>\(g(s,a,s') \;\;\colon \mathcal{S} \times \mathcal{A} \times \mathcal{S} \rightarrow \mathbb{R}\)</dd>
        <dt>報酬関数値の上限</dt><dd>\(R_{\mathrm{max}} \;\;\colon= |g(s, a)| \le R_{\mathrm{max}}, \forall(s, a) \in \mathcal{S} \times \mathcal{A} \)</dd>
        <dt>確率的方策</dt><dd>\(\pi \;\;\colon\;\;\mathcal{A}\times\mathcal{S} \rightarrow [0,1] \;\; | \;\; \sum_{a \in \mathcal{A}} \pi(a|s) = 1, \forall s \in \mathcal{S}\)</dd>
        <dt>確率的方策の集合</dt><dd>\(\Pi \;\; \colon= \;\; \{\pi : \mathcal{A} \times \mathcal{S} \rightarrow [0,1] \;\; | \;\; \sum_{a \in \mathcal{A}} \pi(a|s) = 1, \; \forall s \in \mathcal{S}\}\)</dd>
        <dt>決定的方策</dt><dd>\(\pi^{\rm d} : \mathcal{S} \rightarrow \mathcal{A} \)</dd>
        <dt>決定的方策の集合</dt><dd>\(\Pi^{\rm d} \;\; \colon= \;\; \{\pi^{\rm d} : \mathcal{S} \rightarrow \mathcal{A} \}\)</dd>
        <dt>マルコフ決定過程</dt><dd>\({\rm M} \;\; \colon= \;\; \{\mathcal{S}, \mathcal{A}, p_{s_0}, p_T, g\}\)</dd>
        <dt>方策\(\pi\)に従うマルコフ決定過程</dt><dd>\({\rm M}(\pi) \;\; \colon= \;\; \{\mathcal{S}, \mathcal{A}, p_{s_0}, p_T, g, \pi\}\)</dd>
        <dt>リターン（割引累積報酬）の割引率</dt><dd>\(\gamma \in [0,1)\)</dd>
        <dt>時間ステップ\(t\)の収益の確率変数</dt><dd>\(C_t \;\; \colon= \;\; \sum^{\infty}_{k=0} \gamma^kR_{t+k}\)</dd>
        <dt>時間ステップ\(t\)の収益の実現値</dt><dd>\(c_t\)</dd>
        <dt>方策\(\pi\)のベルマン期待作用素</dt><dd>\({\rm B}_{\pi}\)</dd>
        <dt>方策\(\pi\)のベルマン最適作用素</dt><dd>\({\rm B}*\)</dd>
        <dt>方策の系列</dt><dd>\(\bm{\pi} \;\; \colon= \;\; \{\pi_0, \ldots\}\)</dd>
        <dt>(非定常な)マルコフ方策系列の集合</dt><dd>\({\rm \Pi^{M}}\)</dd>
        <dt>定常なマルコフ方策系列の集合</dt><dd> \({\rm \Pi^{S}}\)</dd>
        <dt>定常な決定的マルコフ方策系列の集合</dt><dd> \({\rm \Pi^{SD}}\)</dd>
        <dt>履歴依存の方策決定系列の集合</dt><dd> \({\rm \Pi^{H}}\)</dd>
        </dl>
        </div></div> 

        </div></div>
    <h2>参考文献、サイト</h2>
        <div><div class="hidden_show">
        <ol>

            <li><a href="https://en.wikipedia.org/wiki/List_of_mathematical_symbols_by_subject">"list of matthematical symbols by subject", Wikipedia the free encyclopedia</a></li>
            <li><a href="http://bookclub.kodansha.co.jp/product?item=0000275420">森村哲郎, "強化学習", 2019, 講談社</a></li>
        </ol>
        </div></div> 
    </div></div>
<div class="end_of_page_margin"></div>
<div class="end_of_page">
<a class="prev" href="01_introduction/01_about/02_contact.html">連絡先</a>
<a class="upper" href="index.html">上：ホーム</a>
<a class="next" href="01_introduction/01_about/04_references_for_introduction.html">参考資料（このサイトについて)</a>
</div>
</main>
</body>
</html>
